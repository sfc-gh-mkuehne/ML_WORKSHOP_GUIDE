{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End ML Workflow in Snowflake\n",
    "\n",
    "Welcome to the ML workflow notebook! In this hands-on session, you will learn how to build, train, deploy, and monitor a machine learning model entirely within Snowflake.\n",
    "\n",
    "---\n",
    "\n",
    "## What We Will Build\n",
    "\n",
    "We will create a complete ML pipeline to **predict daily first-time player conversions** for marketing campaigns. The workflow covers:\n",
    "\n",
    "| Stage | Snowflake Capability | What You Will Learn |\n",
    "|-------|---------------------|---------------------|\n",
    "| 1. Data Exploration | Snowpark DataFrames | Load and explore data with Python |\n",
    "| 2. Feature Engineering | Feature Store | Create reusable, governed features |\n",
    "| 3. Preprocessing | ML Transformers | Encode, scale, and prepare data |\n",
    "| 4. Experiment Tracking | MLflow Integration | Track experiments and compare runs |\n",
    "| 5. Model Training | Snowpark ML | Train XGBoost with hyperparameter tuning |\n",
    "| 6. Model Management | Model Registry | Version and govern your models |\n",
    "| 7. Deployment | Batch Inference | Score new data at scale |\n",
    "| 8. Orchestration | ML Jobs | Schedule automated pipelines |\n",
    "| 9. Monitoring | Prediction Quality | Track model performance over time |\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have completed:\n",
    "- `01_setup_and_data_generation.ipynb` (creates database, tables, and sample data)\n",
    "\n",
    "---\n",
    "\n",
    "## Snowflake ML Capabilities Overview\n",
    "\n",
    "Snowflake provides a comprehensive set of ML tools that work together:\n",
    "\n",
    "**Data Manipulation:**\n",
    "- Snowpark DataFrames (pandas-like syntax)\n",
    "- SQL integration\n",
    "- Pandas API on Snowpark\n",
    "\n",
    "**Feature Engineering:**\n",
    "- Feature Store for governed, reusable features\n",
    "- Point-in-time lookups to prevent data leakage\n",
    "- Feature pipelines for complex transformations\n",
    "\n",
    "**Preprocessing (snowflake.ml.modeling.preprocessing):**\n",
    "- OneHotEncoder, OrdinalEncoder - Categorical encoding\n",
    "- StandardScaler, MinMaxScaler, MaxAbsScaler - Numeric scaling\n",
    "- LabelEncoder - Target encoding\n",
    "- SimpleImputer - Missing value handling\n",
    "- Pipeline - Chain multiple transformers\n",
    "\n",
    "**Model Training (snowflake.ml.modeling):**\n",
    "- XGBoost, LightGBM, CatBoost - Gradient boosting\n",
    "- RandomForest, GradientBoosting - Ensemble methods\n",
    "- LinearRegression, LogisticRegression - Linear models\n",
    "- GridSearchCV, RandomizedSearchCV - Hyperparameter tuning\n",
    "\n",
    "**Experiment Tracking:**\n",
    "- MLflow integration for logging parameters and metrics\n",
    "- Compare runs across experiments\n",
    "- Visualize training progress\n",
    "\n",
    "**Model Management:**\n",
    "- Model Registry for versioning\n",
    "- Lineage tracking\n",
    "- Deployment-ready models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: Environment Setup and Imports\n",
    "\n",
    "### What We Are Doing\n",
    "Setting up the Snowpark session and importing the necessary libraries for our ML workflow.\n",
    "\n",
    "### Snowflake Notebook Tip\n",
    "In Snowflake Notebooks, the session is automatically available. You can switch between SQL and Python cells seamlessly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core Snowpark libraries\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "import snowflake.snowpark.functions as F\n",
    "from snowflake.snowpark.types import *\n",
    "\n",
    "# Import ML libraries\n",
    "from snowflake.ml.modeling.preprocessing import (\n",
    "    OneHotEncoder, \n",
    "    OrdinalEncoder, \n",
    "    StandardScaler, \n",
    "    MinMaxScaler,\n",
    "    LabelEncoder\n",
    ")\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "from snowflake.ml.modeling.xgboost import XGBRegressor\n",
    "from snowflake.ml.modeling.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Import Feature Store\n",
    "from snowflake.ml.feature_store import (\n",
    "    FeatureStore, \n",
    "    FeatureView, \n",
    "    Entity,\n",
    "    CreationMode\n",
    ")\n",
    "\n",
    "# Import Model Registry\n",
    "from snowflake.ml.registry import Registry\n",
    "\n",
    "# Import for experiment tracking\n",
    "import snowflake.ml.mlflow as mlflow\n",
    "\n",
    "# Standard Python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Get the active session (automatically available in Snowflake Notebooks)\n",
    "session = get_active_session()\n",
    "\n",
    "# Set the context\n",
    "session.use_database(\"ML_WORKFLOW_DEMO\")\n",
    "session.use_schema(\"WORKSHOP\")\n",
    "session.use_warehouse(\"ML_COMPUTE_WH\")\n",
    "\n",
    "print(\"Session established successfully!\")\n",
    "print(f\"Current database: {session.get_current_database()}\")\n",
    "print(f\"Current schema: {session.get_current_schema()}\")\n",
    "print(f\"Current warehouse: {session.get_current_warehouse()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Data Exploration with Snowpark\n",
    "\n",
    "### What We Are Doing\n",
    "Loading our tables into Snowpark DataFrames and exploring the data using Python syntax.\n",
    "\n",
    "### Why This Matters\n",
    "Snowpark allows you to work with data using familiar pandas-like operations while keeping all computation in Snowflake. This means:\n",
    "- No data movement to your local machine\n",
    "- Scalable processing on Snowflake's compute\n",
    "- Seamless integration with SQL when needed\n",
    "\n",
    "### Snowflake Capabilities: Snowpark DataFrames\n",
    "- **Lazy Evaluation**: Operations are not executed until you call `.collect()`, `.show()`, or `.to_pandas()`\n",
    "- **Pushdown Optimization**: All operations are translated to SQL and run on Snowflake\n",
    "- **Pandas API**: Use `.to_pandas()` for local analysis or use Snowpark pandas API for distributed pandas operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tables into Snowpark DataFrames\n",
    "# This does NOT load data into memory - it creates a reference to the table\n",
    "\n",
    "jackpot_df = session.table(\"JACKPOT\")\n",
    "ftmp_df = session.table(\"FTMP\")\n",
    "sales_df = session.table(\"SALES\")\n",
    "marketing_df = session.table(\"MARKETING\")\n",
    "upcoming_df = session.table(\"UPCOMING_CAMPAIGNS\")\n",
    "\n",
    "# Check row counts\n",
    "print(\"Table Row Counts:\")\n",
    "print(f\"  JACKPOT: {jackpot_df.count():,} rows\")\n",
    "print(f\"  FTMP: {ftmp_df.count():,} rows\")\n",
    "print(f\"  SALES: {sales_df.count():,} rows\")\n",
    "print(f\"  MARKETING: {marketing_df.count():,} rows\")\n",
    "print(f\"  UPCOMING_CAMPAIGNS: {upcoming_df.count():,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the schema of each table\n",
    "print(\"JACKPOT Schema:\")\n",
    "jackpot_df.schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the FTMP table (our target variable)\n",
    "# .show() displays results without collecting to local memory\n",
    "ftmp_df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the target variable distribution\n",
    "# Using Snowpark aggregation functions\n",
    "\n",
    "ftmp_stats = ftmp_df.select(\n",
    "    F.count(\"FTMP\").alias(\"count\"),\n",
    "    F.avg(\"FTMP\").alias(\"mean\"),\n",
    "    F.stddev(\"FTMP\").alias(\"std\"),\n",
    "    F.min(\"FTMP\").alias(\"min\"),\n",
    "    F.max(\"FTMP\").alias(\"max\"),\n",
    "    F.median(\"FTMP\").alias(\"median\")\n",
    ")\n",
    "\n",
    "print(\"FTMP (Target Variable) Statistics:\")\n",
    "ftmp_stats.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the aggregated training dataset\n",
    "# We predict TOTAL daily FTMP (aggregated across all sites/channels)\n",
    "\n",
    "# Step 1: Aggregate FTMP by date\n",
    "daily_ftmp = ftmp_df.group_by(\"FTMP_DATE\").agg(\n",
    "    F.sum(\"FTMP\").alias(\"TOTAL_FTMP\")\n",
    ").with_column_renamed(\"FTMP_DATE\", \"DATE\")\n",
    "\n",
    "print(\"Daily FTMP (aggregated):\")\n",
    "daily_ftmp.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Aggregate marketing spend by date and channel\n",
    "# First, handle NULL channel_code values by replacing with 'ORGANIC'\n",
    "marketing_clean = marketing_df.with_column(\n",
    "    \"CHANNEL_CODE\",\n",
    "    F.coalesce(F.col(\"CHANNEL_CODE\"), F.lit(\"ORGANIC\"))\n",
    ").with_column(\n",
    "    \"COSTS_NUM\",\n",
    "    F.col(\"COSTS\").cast(\"FLOAT\")\n",
    ")\n",
    "\n",
    "# Aggregate total daily marketing spend\n",
    "daily_marketing = marketing_clean.group_by(\"DAT\").agg(\n",
    "    F.sum(\"COSTS_NUM\").alias(\"TOTAL_MARKETING_SPEND\")\n",
    ").with_column_renamed(\"DAT\", \"DATE\")\n",
    "\n",
    "print(\"Daily Marketing Spend:\")\n",
    "daily_marketing.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Aggregate sales by date\n",
    "daily_sales = sales_df.group_by(\"DAT\").agg(\n",
    "    F.sum(\"CUSTOMER_COUNTS\").alias(\"TOTAL_CUSTOMERS\"),\n",
    "    F.sum(\"SUM\").alias(\"TOTAL_REVENUE\")\n",
    ").with_column_renamed(\"DAT\", \"DATE\")\n",
    "\n",
    "print(\"Daily Sales:\")\n",
    "daily_sales.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Prepare jackpot data (already at daily level)\n",
    "jackpot_clean = jackpot_df.select(\n",
    "    F.col(\"DS\").alias(\"DATE\"),\n",
    "    F.col(\"EJ_JP\"),\n",
    "    F.col(\"LOTTO_JP\"),\n",
    "    F.col(\"IS_EJ_DRAW_DATE\"),\n",
    "    F.col(\"IS_LOTTO_DRAW_DATE\"),\n",
    "    F.col(\"IS_EJ_MAX_JP\")\n",
    ")\n",
    "\n",
    "print(\"Jackpot Data:\")\n",
    "jackpot_clean.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Join all data sources\n",
    "# This creates our base training dataset\n",
    "\n",
    "training_base = daily_ftmp.join(\n",
    "    jackpot_clean,\n",
    "    daily_ftmp[\"DATE\"] == jackpot_clean[\"DATE\"],\n",
    "    \"inner\"\n",
    ").drop(jackpot_clean[\"DATE\"])\n",
    "\n",
    "training_base = training_base.join(\n",
    "    daily_marketing,\n",
    "    training_base[\"DATE\"] == daily_marketing[\"DATE\"],\n",
    "    \"left\"\n",
    ").drop(daily_marketing[\"DATE\"])\n",
    "\n",
    "training_base = training_base.join(\n",
    "    daily_sales,\n",
    "    training_base[\"DATE\"] == daily_sales[\"DATE\"],\n",
    "    \"left\"\n",
    ").drop(daily_sales[\"DATE\"])\n",
    "\n",
    "# Fill nulls in aggregated columns with 0\n",
    "training_base = training_base.na.fill({\n",
    "    \"TOTAL_MARKETING_SPEND\": 0,\n",
    "    \"TOTAL_CUSTOMERS\": 0,\n",
    "    \"TOTAL_REVENUE\": 0\n",
    "})\n",
    "\n",
    "print(f\"Training dataset: {training_base.count()} rows\")\n",
    "training_base.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Feature Engineering with Feature Store\n",
    "\n",
    "### What We Are Doing\n",
    "Creating reusable, governed features using Snowflake's Feature Store.\n",
    "\n",
    "### Why This Matters\n",
    "The Feature Store provides:\n",
    "- **Reusability**: Define features once, use them across multiple models\n",
    "- **Governance**: Track feature lineage and ownership\n",
    "- **Consistency**: Ensure training and inference use the same feature definitions\n",
    "- **Point-in-Time Correctness**: Prevent data leakage with proper temporal joins\n",
    "\n",
    "### Snowflake Feature Store Capabilities\n",
    "\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| **Entity** | The primary key for features (e.g., DATE, USER_ID) |\n",
    "| **FeatureView** | A collection of related features tied to an entity |\n",
    "| **Spine DataFrame** | The dataset you want to enrich with features |\n",
    "| **retrieve_feature_values()** | Get feature values for training or inference |\n",
    "### UI Guide: Viewing the Feature Store\n",
    "\n",
    "After running this section, you can explore your features in Snowsight:\n",
    "1. Navigate to **Data** in the left sidebar\n",
    "2. Click on **Feature Store** (under the AI/ML section)\n",
    "3. You will see your registered entities and feature views\n",
    "4. Click on a feature view to see:\n",
    "   - Feature definitions\n",
    "   - Data lineage\n",
    "   - Usage statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Feature Store\n",
    "fs = FeatureStore(\n",
    "    session=session,\n",
    "    database=\"ML_WORKFLOW_DEMO\",\n",
    "    name=\"WORKSHOP\",\n",
    "    default_warehouse=\"ML_COMPUTE_WH\",\n",
    "    creation_mode=CreationMode.CREATE_IF_NOT_EXIST\n",
    ")\n",
    "\n",
    "print(\"Feature Store initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Entity for our features\n",
    "# The Entity defines the primary key (join key) for features\n",
    "\n",
    "date_entity = Entity(\n",
    "    name=\"DAILY_DATE\",\n",
    "    join_keys=[\"DATE\"],\n",
    "    desc=\"Daily date entity for time-series features\"\n",
    ")\n",
    "\n",
    "# Register the entity\n",
    "fs.register_entity(date_entity)\n",
    "print(\"Entity 'DAILY_DATE' registered successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training base as a table for the Feature Store\n",
    "training_base.write.save_as_table(\"TRAINING_BASE\", mode=\"overwrite\")\n",
    "\n",
    "# Create feature engineering transformations\n",
    "# Add day of week, month features, and lagged values\n",
    "\n",
    "feature_sql = \"\"\"\n",
    "SELECT \n",
    "    DATE,\n",
    "    -- Target variable\n",
    "    TOTAL_FTMP,\n",
    "    \n",
    "    -- Log-transform the target (handles skewness)\n",
    "    LN(TOTAL_FTMP + 1) as LOG_FTMP,\n",
    "    \n",
    "    -- Jackpot features (already numeric)\n",
    "    EJ_JP,\n",
    "    LOTTO_JP,\n",
    "    EJ_JP / 1000000.0 as EJ_JP_MILLIONS,\n",
    "    LOTTO_JP / 1000000.0 as LOTTO_JP_MILLIONS,\n",
    "    \n",
    "    -- Boolean features\n",
    "    IS_EJ_DRAW_DATE,\n",
    "    IS_LOTTO_DRAW_DATE,\n",
    "    IS_EJ_MAX_JP,\n",
    "    \n",
    "    -- Marketing and sales features\n",
    "    TOTAL_MARKETING_SPEND,\n",
    "    TOTAL_CUSTOMERS,\n",
    "    TOTAL_REVENUE,\n",
    "    \n",
    "    -- Temporal features\n",
    "    DAYOFWEEK(TO_DATE(DATE)) as DAY_OF_WEEK,\n",
    "    MONTH(TO_DATE(DATE)) as MONTH,\n",
    "    DAYOFMONTH(TO_DATE(DATE)) as DAY_OF_MONTH,\n",
    "    WEEKOFYEAR(TO_DATE(DATE)) as WEEK_OF_YEAR,\n",
    "    \n",
    "    -- Weekend indicator\n",
    "    CASE WHEN DAYOFWEEK(TO_DATE(DATE)) IN (0, 6) THEN 1 ELSE 0 END as IS_WEEKEND,\n",
    "    \n",
    "    -- Lagged features (previous day values)\n",
    "    LAG(TOTAL_MARKETING_SPEND, 1) OVER (ORDER BY DATE) as MARKETING_SPEND_LAG1,\n",
    "    LAG(TOTAL_MARKETING_SPEND, 7) OVER (ORDER BY DATE) as MARKETING_SPEND_LAG7,\n",
    "    LAG(EJ_JP, 1) OVER (ORDER BY DATE) as EJ_JP_LAG1,\n",
    "    LAG(TOTAL_FTMP, 1) OVER (ORDER BY DATE) as FTMP_LAG1,\n",
    "    LAG(TOTAL_FTMP, 7) OVER (ORDER BY DATE) as FTMP_LAG7,\n",
    "    \n",
    "    -- Rolling averages\n",
    "    AVG(TOTAL_MARKETING_SPEND) OVER (ORDER BY DATE ROWS BETWEEN 7 PRECEDING AND 1 PRECEDING) as MARKETING_SPEND_ROLLING_7D,\n",
    "    AVG(TOTAL_FTMP) OVER (ORDER BY DATE ROWS BETWEEN 7 PRECEDING AND 1 PRECEDING) as FTMP_ROLLING_7D\n",
    "    \n",
    "FROM TRAINING_BASE\n",
    "ORDER BY DATE\n",
    "\"\"\"\n",
    "\n",
    "# Create the feature dataset\n",
    "feature_df = session.sql(feature_sql)\n",
    "\n",
    "# Remove rows with NULL lagged features (first few rows)\n",
    "feature_df = feature_df.na.drop()\n",
    "\n",
    "print(f\"Feature dataset: {feature_df.count()} rows\")\n",
    "feature_df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the feature data as a table\n",
    "feature_df.write.save_as_table(\"DAILY_FEATURES\", mode=\"overwrite\")\n",
    "\n",
    "# Create a Feature View from the feature table\n",
    "daily_features_fv = FeatureView(\n",
    "    name=\"DAILY_CONVERSION_FEATURES\",\n",
    "    entities=[date_entity],\n",
    "    feature_df=session.table(\"DAILY_FEATURES\"),\n",
    "    desc=\"Daily features for conversion prediction including jackpots, marketing, and temporal features\"\n",
    ")\n",
    "\n",
    "# Register the Feature View\n",
    "daily_features_fv = fs.register_feature_view(\n",
    "    feature_view=daily_features_fv,\n",
    "    version=\"V1\",\n",
    "    block=True  # Wait for registration to complete\n",
    ")\n",
    "\n",
    "print(\"Feature View 'DAILY_CONVERSION_FEATURES' registered successfully!\")\n",
    "print(f\"Version: {daily_features_fv.version}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all registered Feature Views\n",
    "print(\"Registered Feature Views:\")\n",
    "for fv in fs.list_feature_views().collect():\n",
    "    print(f\"  - {fv['NAME']} (Version: {fv['VERSION']})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Data Preprocessing with Snowflake ML\n",
    "\n",
    "### What We Are Doing\n",
    "Applying preprocessing transformations to prepare our features for model training.\n",
    "\n",
    "### Why This Matters\n",
    "Proper preprocessing ensures:\n",
    "- Categorical variables are encoded for ML algorithms\n",
    "- Numeric features are scaled for optimal model performance\n",
    "- The same transformations are applied consistently during training and inference\n",
    "\n",
    "### Snowflake ML Preprocessing Capabilities\n",
    "\n",
    "| Transformer | Description | Use Case |\n",
    "|-------------|-------------|----------|\n",
    "| **OrdinalEncoder** | Maps categories to integers | Ordinal categories (low/medium/high) |\n",
    "| **OneHotEncoder** | Creates binary columns for each category | Nominal categories (colors, countries) |\n",
    "| **StandardScaler** | Scales to zero mean, unit variance | Most ML algorithms |\n",
    "| **MinMaxScaler** | Scales to [0, 1] range | Neural networks, distance-based algorithms |\n",
    "| **MaxAbsScaler** | Scales by maximum absolute value | Sparse data |\n",
    "| **LabelEncoder** | Encodes target labels | Classification targets |\n",
    "| **SimpleImputer** | Fills missing values | Handling NULLs |\n",
    "| **Pipeline** | Chains multiple transformers | Complex preprocessing workflows |\n",
    "\n",
    "### Key Concept: Fit vs Transform\n",
    "\n",
    "- **fit()**: Learn parameters from training data (e.g., mean/std for scaling)\n",
    "- **transform()**: Apply learned parameters to new data\n",
    "- **fit_transform()**: Do both in one step (training only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the feature data for preprocessing\n",
    "features_df = session.table(\"DAILY_FEATURES\")\n",
    "\n",
    "# Define feature columns and target\n",
    "TARGET_COL = \"LOG_FTMP\"  # We use log-transformed target\n",
    "NUMERIC_FEATURES = [\n",
    "    \"EJ_JP_MILLIONS\", \"LOTTO_JP_MILLIONS\", \n",
    "    \"TOTAL_MARKETING_SPEND\", \"TOTAL_CUSTOMERS\", \"TOTAL_REVENUE\",\n",
    "    \"MARKETING_SPEND_LAG1\", \"MARKETING_SPEND_LAG7\", \"EJ_JP_LAG1\",\n",
    "    \"FTMP_LAG1\", \"FTMP_LAG7\", \"MARKETING_SPEND_ROLLING_7D\", \"FTMP_ROLLING_7D\"\n",
    "]\n",
    "CATEGORICAL_FEATURES = [\"DAY_OF_WEEK\", \"MONTH\"]\n",
    "BOOLEAN_FEATURES = [\"IS_EJ_DRAW_DATE\", \"IS_LOTTO_DRAW_DATE\", \"IS_EJ_MAX_JP\", \"IS_WEEKEND\"]\n",
    "\n",
    "print(f\"Target: {TARGET_COL}\")\n",
    "print(f\"Numeric features ({len(NUMERIC_FEATURES)}): {NUMERIC_FEATURES}\")\n",
    "print(f\"Categorical features ({len(CATEGORICAL_FEATURES)}): {CATEGORICAL_FEATURES}\")\n",
    "print(f\"Boolean features ({len(BOOLEAN_FEATURES)}): {BOOLEAN_FEATURES}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing transformers\n",
    "\n",
    "# StandardScaler for numeric features\n",
    "# Scales features to have mean=0 and std=1\n",
    "numeric_scaler = StandardScaler(\n",
    "    input_cols=NUMERIC_FEATURES,\n",
    "    output_cols=[f\"{col}_SCALED\" for col in NUMERIC_FEATURES]\n",
    ")\n",
    "\n",
    "# OrdinalEncoder for categorical features\n",
    "# Converts categories to integers\n",
    "categorical_encoder = OrdinalEncoder(\n",
    "    input_cols=CATEGORICAL_FEATURES,\n",
    "    output_cols=[f\"{col}_ENCODED\" for col in CATEGORICAL_FEATURES]\n",
    ")\n",
    "\n",
    "print(\"Preprocessors created:\")\n",
    "print(\"  - StandardScaler for numeric features\")\n",
    "print(\"  - OrdinalEncoder for categorical features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets (80/20 split by date)\n",
    "# Time-series split: use earlier dates for training, later dates for testing\n",
    "\n",
    "# Get the date range\n",
    "date_stats = features_df.select(\n",
    "    F.min(\"DATE\").alias(\"min_date\"),\n",
    "    F.max(\"DATE\").alias(\"max_date\"),\n",
    "    F.count(\"DATE\").alias(\"total_rows\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"Date range: {date_stats['MIN_DATE']} to {date_stats['MAX_DATE']}\")\n",
    "print(f\"Total rows: {date_stats['TOTAL_ROWS']}\")\n",
    "\n",
    "# Calculate split date (80% of data for training)\n",
    "split_index = int(date_stats['TOTAL_ROWS'] * 0.8)\n",
    "\n",
    "# Get all dates sorted\n",
    "all_dates = features_df.select(\"DATE\").distinct().sort(\"DATE\").collect()\n",
    "split_date = all_dates[split_index]['DATE']\n",
    "\n",
    "print(f\"Split date: {split_date}\")\n",
    "print(f\"Training: dates before {split_date}\")\n",
    "print(f\"Testing: dates on or after {split_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "train_df = features_df.filter(F.col(\"DATE\") < split_date)\n",
    "test_df = features_df.filter(F.col(\"DATE\") >= split_date)\n",
    "\n",
    "print(f\"Training set: {train_df.count()} rows\")\n",
    "print(f\"Test set: {test_df.count()} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training data\n",
    "# fit_transform learns the parameters AND applies the transformation\n",
    "\n",
    "train_scaled = numeric_scaler.fit(train_df).transform(train_df)\n",
    "train_encoded = categorical_encoder.fit(train_scaled).transform(train_scaled)\n",
    "\n",
    "# Transform the test data using the same fitted transformers\n",
    "# This ensures consistent preprocessing between train and test\n",
    "test_scaled = numeric_scaler.transform(test_df)\n",
    "test_encoded = categorical_encoder.transform(test_scaled)\n",
    "\n",
    "print(\"Preprocessing complete!\")\n",
    "print(f\"Training columns: {len(train_encoded.columns)}\")\n",
    "train_encoded.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Experiment Tracking with MLflow\n",
    "\n",
    "### What We Are Doing\n",
    "Setting up experiment tracking to log parameters, metrics, and models for each training run.\n",
    "\n",
    "### Why This Matters\n",
    "Experiment tracking enables:\n",
    "- **Reproducibility**: Record exactly what was done for each experiment\n",
    "- **Comparison**: Compare different model versions and hyperparameters\n",
    "- **Collaboration**: Share experiment results with team members\n",
    "- **Governance**: Track model lineage from data to deployment\n",
    "\n",
    "### Snowflake MLflow Integration\n",
    "\n",
    "Snowflake provides native MLflow integration that:\n",
    "- Stores experiment data in Snowflake tables (no external server needed)\n",
    "- Integrates with the Model Registry\n",
    "- Provides a UI for comparing runs\n",
    "\n",
    "### UI Guide: Viewing Experiments in Snowsight\n",
    "\n",
    "After running experiments, you can view them in Snowsight:\n",
    "1. Navigate to **AI / ML** in the left sidebar\n",
    "2. Click on **Experiments**\n",
    "3. You will see a list of all experiments\n",
    "4. Click on an experiment to see:\n",
    "   - Individual runs\n",
    "   - Parameters and metrics for each run\n",
    "   - Comparison charts\n",
    "   - Model artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up MLflow experiment\n",
    "# The experiment name groups all related runs together\n",
    "\n",
    "EXPERIMENT_NAME = \"FTMP_Conversion_Prediction\"\n",
    "\n",
    "# Create or get the experiment\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "print(f\"Experiment '{EXPERIMENT_NAME}' is ready for tracking!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Model Training\n",
    "\n",
    "### What We Are Doing\n",
    "Training XGBoost regression models with different hyperparameters and comparing their performance.\n",
    "\n",
    "### Why This Matters\n",
    "- XGBoost is a powerful gradient boosting algorithm that works well with tabular data\n",
    "- Hyperparameter tuning can significantly improve model performance\n",
    "- Tracking experiments allows us to find the best model configuration\n",
    "\n",
    "### Snowflake ML Training Capabilities\n",
    "\n",
    "**Available Algorithms (snowflake.ml.modeling):**\n",
    "\n",
    "| Category | Algorithms |\n",
    "|----------|------------|\n",
    "| **Gradient Boosting** | XGBRegressor, XGBClassifier, LightGBMRegressor, LightGBMClassifier |\n",
    "| **Ensemble** | RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor |\n",
    "| **Linear** | LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet |\n",
    "| **Tuning** | GridSearchCV, RandomizedSearchCV |\n",
    "\n",
    "### Key Hyperparameters for XGBoost\n",
    "\n",
    "| Parameter | Description | Typical Range |\n",
    "|-----------|-------------|---------------|\n",
    "| **n_estimators** | Number of trees | 100-1000 |\n",
    "| **max_depth** | Maximum tree depth | 3-10 |\n",
    "| **learning_rate** | Step size for updates | 0.01-0.3 |\n",
    "| **subsample** | Fraction of samples per tree | 0.6-1.0 |\n",
    "| **colsample_bytree** | Fraction of features per tree | 0.6-1.0 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare feature columns for training\n",
    "SCALED_FEATURES = [f\"{col}_SCALED\" for col in NUMERIC_FEATURES]\n",
    "ENCODED_FEATURES = [f\"{col}_ENCODED\" for col in CATEGORICAL_FEATURES]\n",
    "ALL_FEATURES = SCALED_FEATURES + ENCODED_FEATURES + BOOLEAN_FEATURES\n",
    "\n",
    "print(f\"Total features for training: {len(ALL_FEATURES)}\")\n",
    "print(f\"Features: {ALL_FEATURES}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter configurations to try\n",
    "hyperparameter_configs = [\n",
    "    {\n",
    "        \"name\": \"baseline\",\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 3,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"subsample\": 0.8\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"deeper_trees\",\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 6,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"subsample\": 0.8\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"more_trees_slower_lr\",\n",
    "        \"n_estimators\": 200,\n",
    "        \"max_depth\": 4,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"subsample\": 0.8\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Will train {len(hyperparameter_configs)} model configurations\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models and track experiments\n",
    "results = []\n",
    "\n",
    "for config in hyperparameter_configs:\n",
    "    print(f\"\\nTraining model: {config['name']}\")\n",
    "    \n",
    "    # Start an MLflow run\n",
    "    with mlflow.start_run(run_name=config['name']) as run:\n",
    "        # Log hyperparameters\n",
    "        mlflow.log_param(\"n_estimators\", config['n_estimators'])\n",
    "        mlflow.log_param(\"max_depth\", config['max_depth'])\n",
    "        mlflow.log_param(\"learning_rate\", config['learning_rate'])\n",
    "        mlflow.log_param(\"subsample\", config['subsample'])\n",
    "        mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "        \n",
    "        # Create and train the model\n",
    "        model = XGBRegressor(\n",
    "            input_cols=ALL_FEATURES,\n",
    "            label_cols=[TARGET_COL],\n",
    "            output_cols=[\"PREDICTION\"],\n",
    "            n_estimators=config['n_estimators'],\n",
    "            max_depth=config['max_depth'],\n",
    "            learning_rate=config['learning_rate'],\n",
    "            subsample=config['subsample'],\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(train_encoded)\n",
    "        \n",
    "        # Make predictions on test set\n",
    "        test_predictions = model.predict(test_encoded)\n",
    "        \n",
    "        # Convert to pandas for metrics calculation\n",
    "        test_results_pd = test_predictions.select(\n",
    "            TARGET_COL, \"PREDICTION\"\n",
    "        ).to_pandas()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mae = np.mean(np.abs(test_results_pd[TARGET_COL] - test_results_pd[\"PREDICTION\"]))\n",
    "        rmse = np.sqrt(np.mean((test_results_pd[TARGET_COL] - test_results_pd[\"PREDICTION\"])**2))\n",
    "        \n",
    "        # Calculate R2\n",
    "        ss_res = np.sum((test_results_pd[TARGET_COL] - test_results_pd[\"PREDICTION\"])**2)\n",
    "        ss_tot = np.sum((test_results_pd[TARGET_COL] - test_results_pd[TARGET_COL].mean())**2)\n",
    "        r2 = 1 - (ss_res / ss_tot)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"name\": config['name'],\n",
    "            \"run_id\": run.info.run_id,\n",
    "            \"mae\": mae,\n",
    "            \"rmse\": rmse,\n",
    "            \"r2\": r2,\n",
    "            \"model\": model\n",
    "        })\n",
    "        \n",
    "        print(f\"  MAE: {mae:.4f}\")\n",
    "        print(f\"  RMSE: {rmse:.4f}\")\n",
    "        print(f\"  R2: {r2:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"All training runs completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results and select the best model\n",
    "results_df = pd.DataFrame([\n",
    "    {\"Model\": r[\"name\"], \"MAE\": r[\"mae\"], \"RMSE\": r[\"rmse\"], \"R2\": r[\"r2\"]}\n",
    "    for r in results\n",
    "])\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Select the best model (lowest RMSE)\n",
    "best_result = min(results, key=lambda x: x[\"rmse\"])\n",
    "best_model = best_result[\"model\"]\n",
    "\n",
    "print(f\"\\nBest Model: {best_result['name']}\")\n",
    "print(f\"  RMSE: {best_result['rmse']:.4f}\")\n",
    "print(f\"  R2: {best_result['r2']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 7: Model Registry\n",
    "\n",
    "### What We Are Doing\n",
    "Registering the best model to the Snowflake Model Registry for versioning, governance, and deployment.\n",
    "\n",
    "### Why This Matters\n",
    "The Model Registry provides:\n",
    "- **Version Control**: Track different versions of your models\n",
    "- **Metadata**: Store model descriptions, metrics, and tags\n",
    "- **Lineage**: See what data and features were used to train the model\n",
    "- **Deployment**: Deploy models directly from the registry\n",
    "\n",
    "### Snowflake Model Registry Capabilities\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **log_model()** | Register a new model or version |\n",
    "| **get_model()** | Retrieve a registered model |\n",
    "| **list_models()** | View all registered models |\n",
    "| **run()** | Execute batch inference with a model |\n",
    "| **delete_model()** | Remove a model from the registry |\n",
    "### UI Guide: Viewing the Model Registry\n",
    "\n",
    "After registering a model, explore it in Snowsight:\n",
    "1. Navigate to **AI / ML** in the left sidebar\n",
    "2. Click on **Models** (or Model Registry)\n",
    "3. You will see a list of all registered models\n",
    "4. Click on a model to see:\n",
    "   - All versions\n",
    "   - Metadata and tags\n",
    "   - Lineage information\n",
    "   - Usage history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Model Registry\n",
    "registry = Registry(session=session)\n",
    "\n",
    "# Define model name and version\n",
    "MODEL_NAME = \"FTMP_CONVERSION_PREDICTOR\"\n",
    "MODEL_VERSION = \"V1\"\n",
    "\n",
    "# Register the best model\n",
    "registered_model = registry.log_model(\n",
    "    model=best_model,\n",
    "    model_name=MODEL_NAME,\n",
    "    version_name=MODEL_VERSION,\n",
    "    comment=f\"XGBoost model for daily FTMP prediction. Best config: {best_result['name']}. RMSE: {best_result['rmse']:.4f}\",\n",
    "    metrics={\n",
    "        \"mae\": best_result[\"mae\"],\n",
    "        \"rmse\": best_result[\"rmse\"],\n",
    "        \"r2\": best_result[\"r2\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Model registered successfully!\")\n",
    "print(f\"  Name: {MODEL_NAME}\")\n",
    "print(f\"  Version: {MODEL_VERSION}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all registered models\n",
    "print(\"Registered Models:\")\n",
    "models_df = registry.show_models()\n",
    "models_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the model from the registry\n",
    "# This demonstrates how to load a model for inference\n",
    "retrieved_model = registry.get_model(MODEL_NAME).version(MODEL_VERSION)\n",
    "\n",
    "print(f\"Retrieved model: {MODEL_NAME} version {MODEL_VERSION}\")\n",
    "print(f\"Model type: {type(retrieved_model)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 8: Batch Scoring and Deployment\n",
    "\n",
    "### What We Are Doing\n",
    "Using the registered model and Feature Store together to score new data (upcoming campaigns).\n",
    "\n",
    "### Why This Matters\n",
    "This demonstrates the production inference workflow:\n",
    "1. **Feature Store**: Retrieve or generate features for new data\n",
    "2. **Model Registry**: Load the deployed model\n",
    "3. **Inference**: Apply the model to generate predictions\n",
    "\n",
    "### Production Inference Flow\n",
    "\n",
    "```\n",
    "New Data (UPCOMING_CAMPAIGNS)\n",
    "         |\n",
    "         v\n",
    "Feature Engineering (same transformations)\n",
    "         |\n",
    "         v\n",
    "Preprocessing (fitted transformers)\n",
    "         |\n",
    "         v\n",
    "Model Registry (get_model)\n",
    "         |\n",
    "         v\n",
    "Predictions\n",
    "```\n",
    "\n",
    "### UI Guide: Viewing Model Lineage\n",
    "\n",
    "After running inference, you can see the connection between models and features:\n",
    "1. Navigate to **AI / ML** > **Models**\n",
    "2. Click on your model\n",
    "3. Look for the **Lineage** tab\n",
    "4. This shows:\n",
    "   - Source tables\n",
    "   - Feature views used\n",
    "   - Training data lineage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the upcoming campaigns data\n",
    "upcoming_campaigns = session.table(\"UPCOMING_CAMPAIGNS\")\n",
    "print(f\"Upcoming campaigns to score: {upcoming_campaigns.count()} rows\")\n",
    "upcoming_campaigns.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get the last known feature values for lagged features\n",
    "# For future dates, we need to use historical data for lag features\n",
    "\n",
    "last_training_date = features_df.select(F.max(\"DATE\")).collect()[0][0]\n",
    "last_known_features = features_df.filter(F.col(\"DATE\") == last_training_date).collect()[0]\n",
    "\n",
    "print(f\"Using features from last known date: {last_training_date}\")\n",
    "print(f\"Last FTMP: {last_known_features['TOTAL_FTMP']}\")\n",
    "print(f\"Last Marketing Spend: {last_known_features['TOTAL_MARKETING_SPEND']}\")\n",
    "print(\"\\nThese values will be used for lagged features in future date predictions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Generate features for upcoming campaigns using the SAME logic as training\n",
    "# This ensures consistency - we're applying identical feature engineering\n",
    "\n",
    "# Aggregate upcoming campaigns by date (same as we did for training data)\n",
    "# Cast columns to match DAILY_FEATURES table types\n",
    "upcoming_aggregated = upcoming_campaigns.group_by(\"CAMPAIGN_DATE\").agg(\n",
    "    F.sum(\"PLANNED_COSTS\").cast(\"FLOAT\").alias(\"TOTAL_MARKETING_SPEND\"),\n",
    "    F.max(\"EXPECTED_EJ_JP\").cast(\"FLOAT\").alias(\"EJ_JP\"),\n",
    "    F.max(\"EXPECTED_LOTTO_JP\").cast(\"FLOAT\").alias(\"LOTTO_JP\"),\n",
    "    F.max(F.col(\"IS_EJ_DRAW_DATE\").cast(\"BOOLEAN\")).alias(\"IS_EJ_DRAW_DATE\"),\n",
    "    F.max(F.col(\"IS_LOTTO_DRAW_DATE\").cast(\"BOOLEAN\")).alias(\"IS_LOTTO_DRAW_DATE\")\n",
    ").with_column_renamed(\"CAMPAIGN_DATE\", \"DATE\")\n",
    "\n",
    "# Apply the SAME feature transformations as in Section 3\n",
    "# This is the key to Feature Store consistency!\n",
    "new_features = upcoming_aggregated.with_column(\n",
    "    \"TOTAL_FTMP\", F.lit(None).cast(\"FLOAT\")  # NULL for future dates (we're predicting this!)\n",
    ").with_column(\n",
    "    \"LOG_FTMP\", F.lit(None).cast(\"FLOAT\")    # NULL for future dates\n",
    ").with_column(\n",
    "    \"EJ_JP_MILLIONS\", (F.col(\"EJ_JP\") / 1000000.0).cast(\"FLOAT\")\n",
    ").with_column(\n",
    "    \"LOTTO_JP_MILLIONS\", (F.col(\"LOTTO_JP\") / 1000000.0).cast(\"FLOAT\")\n",
    ").with_column(\n",
    "    \"IS_EJ_MAX_JP\", (F.col(\"EJ_JP\") >= 90000000).cast(\"BOOLEAN\")\n",
    ").with_column(\n",
    "    \"DAY_OF_WEEK\", F.dayofweek(F.to_date(F.col(\"DATE\"))).cast(\"INTEGER\")\n",
    ").with_column(\n",
    "    \"MONTH\", F.month(F.to_date(F.col(\"DATE\"))).cast(\"INTEGER\")\n",
    ").with_column(\n",
    "    \"DAY_OF_MONTH\", F.dayofmonth(F.to_date(F.col(\"DATE\"))).cast(\"INTEGER\")\n",
    ").with_column(\n",
    "    \"WEEK_OF_YEAR\", F.weekofyear(F.to_date(F.col(\"DATE\"))).cast(\"INTEGER\")\n",
    ").with_column(\n",
    "    \"IS_WEEKEND\", F.when(F.dayofweek(F.to_date(F.col(\"DATE\"))).isin([0, 6]), 1).otherwise(0).cast(\"INTEGER\")\n",
    ").with_column(\n",
    "    # Lagged features use last known historical values\n",
    "    \"MARKETING_SPEND_LAG1\", F.lit(float(last_known_features['TOTAL_MARKETING_SPEND']))\n",
    ").with_column(\n",
    "    \"MARKETING_SPEND_LAG7\", F.lit(float(last_known_features['MARKETING_SPEND_LAG7'] or 0))\n",
    ").with_column(\n",
    "    \"EJ_JP_LAG1\", F.lit(float(last_known_features['EJ_JP']))\n",
    ").with_column(\n",
    "    \"FTMP_LAG1\", F.lit(float(last_known_features['TOTAL_FTMP']))\n",
    ").with_column(\n",
    "    \"FTMP_LAG7\", F.lit(float(last_known_features['FTMP_LAG7'] or 0))\n",
    ").with_column(\n",
    "    \"MARKETING_SPEND_ROLLING_7D\", F.lit(float(last_known_features['MARKETING_SPEND_ROLLING_7D'] or 0))\n",
    ").with_column(\n",
    "    \"FTMP_ROLLING_7D\", F.lit(float(last_known_features['FTMP_ROLLING_7D'] or 0))\n",
    ").with_column(\n",
    "    \"TOTAL_CUSTOMERS\", F.lit(float(last_known_features['TOTAL_CUSTOMERS']))\n",
    ").with_column(\n",
    "    \"TOTAL_REVENUE\", F.lit(float(last_known_features['TOTAL_REVENUE']))\n",
    ")\n",
    "\n",
    "print(f\"Generated features for {new_features.count()} future dates\")\n",
    "print(\"Feature columns match DAILY_FEATURES table structure\")\n",
    "new_features.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Insert new features into the Feature Store table (DAILY_FEATURES)\n",
    "# This adds the future dates to the same table used for training\n",
    "\n",
    "# Get the schema of DAILY_FEATURES to ensure column order matches\n",
    "daily_features_schema = session.table(\"DAILY_FEATURES\").schema\n",
    "column_order = [field.name for field in daily_features_schema.fields]\n",
    "print(f\"DAILY_FEATURES columns: {column_order}\")\n",
    "\n",
    "# Select columns from new_features in the same order as DAILY_FEATURES\n",
    "# This ensures the insert will work correctly\n",
    "new_features_ordered = new_features.select(column_order)\n",
    "\n",
    "# Check if these dates already exist (avoid duplicates)\n",
    "existing_dates = session.table(\"DAILY_FEATURES\").select(\"DATE\")\n",
    "new_dates_only = new_features_ordered.join(existing_dates, on=\"DATE\", how=\"left_anti\")\n",
    "\n",
    "row_count = new_dates_only.count()\n",
    "if row_count > 0:\n",
    "    # Append new feature rows to DAILY_FEATURES\n",
    "    new_dates_only.write.mode(\"append\").save_as_table(\"DAILY_FEATURES\")\n",
    "    print(f\"Inserted {row_count} new feature rows into DAILY_FEATURES\")\n",
    "else:\n",
    "    print(\"Feature rows for these dates already exist in DAILY_FEATURES\")\n",
    "\n",
    "# Verify the insertion\n",
    "total_rows = session.table(\"DAILY_FEATURES\").count()\n",
    "print(f\"DAILY_FEATURES now has {total_rows} total rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Retrieve features from the Feature Store using retrieve_feature_values()\n",
    "# This is the KEY step that ensures consistency with training!\n",
    "\n",
    "# Create a spine DataFrame with the dates we want to predict\n",
    "spine_df = upcoming_campaigns.select(\n",
    "    F.col(\"CAMPAIGN_DATE\").alias(\"DATE\")\n",
    ").distinct()\n",
    "\n",
    "print(f\"Retrieving features for {spine_df.count()} dates from Feature Store...\")\n",
    "\n",
    "# Retrieve features using the Feature Store\n",
    "# This uses the SAME Feature View we used for training\n",
    "inference_features = fs.retrieve_feature_values(\n",
    "    spine_df=spine_df,\n",
    "    features=[daily_features_fv],\n",
    "    exclude_columns=[\"TOTAL_FTMP\", \"LOG_FTMP\"]  # Exclude target columns (we're predicting these!)\n",
    ")\n",
    "\n",
    "print(\"Features retrieved from Feature Store!\")\n",
    "print(f\"Columns: {inference_features.columns}\")\n",
    "inference_features.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Apply the SAME preprocessing transformers used during training\n",
    "# The numeric_scaler was fitted on training data - we apply the same transformation\n",
    "inference_processed = numeric_scaler.transform(inference_features)\n",
    "\n",
    "print(\"Preprocessing applied (same StandardScaler from training)\")\n",
    "print(f\"Ready for inference with {len(inference_processed.columns)} columns\")\n",
    "inference_processed.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Make predictions using the model from the Model Registry\n",
    "# This completes the Feature Store + Model Registry workflow:\n",
    "# - Features came from Feature Store (consistent with training)\n",
    "# - Model came from Model Registry (versioned, governed)\n",
    "\n",
    "predictions = retrieved_model.run(inference_processed, function_name=\"predict\")\n",
    "\n",
    "# The prediction is in log scale, so we need to convert back\n",
    "predictions_with_ftmp = predictions.with_column(\n",
    "    \"PREDICTED_FTMP\",\n",
    "    F.exp(F.col(\"PREDICTION\")) - 1  # Reverse the log transformation\n",
    ")\n",
    "\n",
    "# Select final columns\n",
    "final_predictions = predictions_with_ftmp.select(\n",
    "    \"DATE\",\n",
    "    \"TOTAL_MARKETING_SPEND\",\n",
    "    \"EJ_JP_MILLIONS\",\n",
    "    \"IS_EJ_DRAW_DATE\",\n",
    "    \"IS_LOTTO_DRAW_DATE\",\n",
    "    F.round(F.col(\"PREDICTED_FTMP\"), 0).alias(\"PREDICTED_FTMP\")\n",
    ").sort(\"DATE\")\n",
    "\n",
    "print(\"Predictions for Upcoming Campaigns:\")\n",
    "final_predictions.show()\n",
    "\n",
    "# Save predictions to table for monitoring and analysis\n",
    "final_predictions.write.mode(\"overwrite\").save_as_table(\"FTMP_PREDICTIONS\")\n",
    "print(\"\\nPredictions saved to FTMP_PREDICTIONS table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 9: Orchestration with ML Jobs\n",
    "\n",
    "### What We Are Doing\n",
    "Creating a scheduled task to automate the scoring pipeline.\n",
    "\n",
    "### Why This Matters\n",
    "Automation ensures:\n",
    "- Predictions are generated on a regular schedule\n",
    "- No manual intervention required\n",
    "- Consistent, reproducible results\n",
    "\n",
    "### Snowflake Orchestration Capabilities\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Tasks** | Scheduled SQL or Python execution |\n",
    "| **DAGs** | Chain tasks with dependencies |\n",
    "| **Streams** | Trigger on data changes |\n",
    "| **Dynamic Tables** | Automatically refresh materialized views |\n",
    "### UI Guide: Monitoring Tasks\n",
    "\n",
    "After creating a task, monitor it in Snowsight:\n",
    "1. Navigate to **Data** > **Databases** > **ML_WORKFLOW_DEMO**\n",
    "2. Click on **Tasks** under the WORKSHOP schema\n",
    "3. You will see the task with its schedule and status\n",
    "4. Click on the task to see:\n",
    "   - Execution history\n",
    "   - Run duration\n",
    "   - Error logs (if any)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Create a stored procedure to run the scoring pipeline\n",
    "-- This procedure can be scheduled as a task\n",
    "\n",
    "CREATE OR REPLACE PROCEDURE RUN_FTMP_SCORING()\n",
    "RETURNS STRING\n",
    "LANGUAGE SQL\n",
    "AS\n",
    "$$\n",
    "BEGIN\n",
    "    -- In production, this would:\n",
    "    -- 1. Load new campaign data\n",
    "    -- 2. Generate features\n",
    "    -- 3. Apply the model\n",
    "    -- 4. Save predictions\n",
    "    \n",
    "    -- For demo purposes, we'll just update the prediction timestamp\n",
    "    CREATE OR REPLACE TABLE SCORING_LOG AS\n",
    "    SELECT \n",
    "        CURRENT_TIMESTAMP() AS last_run,\n",
    "        'SUCCESS' AS status,\n",
    "        (SELECT COUNT(*) FROM FTMP_PREDICTIONS) AS predictions_count;\n",
    "    \n",
    "    RETURN 'Scoring pipeline completed successfully';\n",
    "END;\n",
    "$$;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Create a scheduled task to run the scoring pipeline daily\n",
    "-- The task is created in SUSPENDED state for safety\n",
    "\n",
    "CREATE OR REPLACE TASK DAILY_FTMP_SCORING\n",
    "    WAREHOUSE = ML_COMPUTE_WH\n",
    "    SCHEDULE = 'USING CRON 0 6 * * * UTC'  -- Run at 6 AM UTC daily\n",
    "    COMMENT = 'Daily scoring of FTMP predictions using registered model'\n",
    "AS\n",
    "    CALL RUN_FTMP_SCORING();\n",
    "\n",
    "-- Note: To activate the task, run: ALTER TASK DAILY_FTMP_SCORING RESUME;\n",
    "-- For the workshop, we'll leave it suspended\n",
    "\n",
    "SELECT 'Task DAILY_FTMP_SCORING created (suspended)' AS status;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- View the task details\n",
    "SHOW TASKS LIKE 'DAILY_FTMP_SCORING';\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UI Guide: Monitoring Tasks\n",
    "\n",
    "Now that you have created the task, explore it in Snowsight:\n",
    "\n",
    "**Step 1: Navigate to Tasks**\n",
    "- Open a new Snowsight tab (Catalog menu is hidden in notebook mode)\n",
    "- Navigate to **Catalog** > **Databases** > **ML_WORKFLOW_DEMO**\n",
    "- Expand the **WORKSHOP** schema\n",
    "- Click on **Tasks**\n",
    "\n",
    "**Step 2: Find Your Task**\n",
    "- Look for `DAILY_FTMP_SCORING` in the tasks list\n",
    "- Click on it to open the task details\n",
    "\n",
    "**Step 3: View Task Configuration**\n",
    "- See the schedule (6 AM UTC daily)\n",
    "- View the SQL command that will be executed\n",
    "- Check the current state (SUSPENDED)\n",
    "\n",
    "**Step 4: Task Management**\n",
    "- To activate: `ALTER TASK DAILY_FTMP_SCORING RESUME;`\n",
    "- To pause: `ALTER TASK DAILY_FTMP_SCORING SUSPEND;`\n",
    "- View execution history after the task runs\n",
    "\n",
    "**Step 5: Monitor Execution**\n",
    "- Once activated, the task runs on schedule\n",
    "- Check the **Run History** tab for execution logs\n",
    "- View duration, status, and any errors\n",
    "\n",
    "> **Note:** For this workshop, we leave the task suspended. In production, you would activate it to run the scoring pipeline automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Section 10: ML Observability with Model Monitor\n\n### What We Are Doing\nCreating a Model Monitor to automatically track prediction quality, detect drift, and monitor model behavior over time.\n\n### Why This Matters\nAccording to [Snowflake ML Observability documentation](https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry/model-observability):\n- **Data Drift**: Input data distributions can change over time\n- **Concept Drift**: The relationship between features and target can shift\n- **Model Degradation**: Prediction accuracy may decrease\n\n### How Model Monitors Work\n\n| Component | Description |\n|-----------|-------------|\n| **Source Table** | Table containing predictions with ID, timestamp, features |\n| **Baseline Table** | Optional reference data for drift comparison |\n| **Aggregation Window** | Time granularity for metrics (minimum 1 day) |\n| **Refresh Interval** | How often the monitor updates |\n\n### Prerequisites\n- Model must be in the Snowflake Model Registry\n- Source table with: ID column, TIMESTAMP_NTZ column, prediction column (NUMBER), feature columns\n- Supports regression and binary classification models\n\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": "-- First, prepare the predictions table with required columns for Model Monitor\n-- Requirements: ID (unique), TIMESTAMP_NTZ, prediction as NUMBER, features\n\nCREATE OR REPLACE TABLE FTMP_PREDICTIONS_FOR_MONITORING AS\nSELECT \n    ROW_NUMBER() OVER (ORDER BY DATE) AS PREDICTION_ID,\n    DATE::TIMESTAMP_NTZ AS PREDICTION_TIMESTAMP,\n    TOTAL_MARKETING_SPEND::NUMBER AS TOTAL_MARKETING_SPEND,\n    EJ_JP_MILLIONS::NUMBER AS EJ_JP_MILLIONS,\n    CASE WHEN IS_EJ_DRAW_DATE THEN 1 ELSE 0 END AS IS_EJ_DRAW_DATE,\n    CASE WHEN IS_LOTTO_DRAW_DATE THEN 1 ELSE 0 END AS IS_LOTTO_DRAW_DATE,\n    PREDICTED_FTMP::NUMBER AS PREDICTED_FTMP\nFROM FTMP_PREDICTIONS;\n\nSELECT * FROM FTMP_PREDICTIONS_FOR_MONITORING;\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": "-- Create the Model Monitor\n-- Note: Model Monitor requires the model to be in the Model Registry\n-- The monitor automatically tracks drift, performance metrics, and data quality\n\nCREATE OR REPLACE MODEL MONITOR FTMP_PREDICTION_MONITOR\n  WITH\n    MODEL = FTMP_CONVERSION_PREDICTOR\n    VERSION = V1\n    FUNCTION = PREDICT\n    SOURCE = FTMP_PREDICTIONS_FOR_MONITORING\n    ID_COLUMNS = (PREDICTION_ID)\n    TIMESTAMP_COLUMN = PREDICTION_TIMESTAMP\n    PREDICTION_SCORE_COLUMNS = (PREDICTED_FTMP)\n    WAREHOUSE = ML_COMPUTE_WH\n    AGGREGATION_WINDOW = '1 day'\n    REFRESH_INTERVAL = '1 day';\n\n-- Note: If you get an error about privileges, ensure you have CREATE MODEL MONITOR on the schema\n-- Also ensure your model is properly registered in the Model Registry\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": "-- View all model monitors in the schema\nSHOW MODEL MONITORS;\n\n-- Get details about the specific monitor\n-- DESCRIBE MODEL MONITOR FTMP_PREDICTION_MONITOR;\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### UI Guide: Viewing the Model Monitor Dashboard\n\nNow that you have created a Model Monitor, explore it in Snowsight:\n\n**Step 1: Navigate to Models**\n- In the left sidebar, click on **AI / ML**\n- Click on **Models**\n\n**Step 2: Find Your Model**\n- Look for `FTMP_CONVERSION_PREDICTOR` in the models list\n- Click on it to open the model details page\n\n**Step 3: View the Monitors Tab**\n- On the model details page, find the **Monitors** section\n- Click on `FTMP_PREDICTION_MONITOR` to view the dashboard\n\n**Step 4: Explore the Dashboard**\nThe Model Monitor dashboard shows:\n- **Prediction Volume**: Number of predictions over time\n- **Drift Metrics**: Distribution changes in features and predictions\n- **Statistical Metrics**: Counts, null values, and data quality\n- **Time Range Selector**: Adjust the date range for analysis\n\n**Step 5: Configure Alerts (Optional)**\n- Click **Settings** to customize which metrics are displayed\n- Use **Compare model** to compare different model versions\n- Set up alerts using Snowflake's notification system\n\n### Querying Monitor Metrics Programmatically\n\nYou can also query monitor metrics using SQL:\n\n```sql\n-- Get drift metrics\nSELECT * FROM TABLE(MODEL_MONITOR_DRIFT_METRIC(\n    'FTMP_PREDICTION_MONITOR',\n    'PSI',  -- Population Stability Index\n    'TOTAL_MARKETING_SPEND',\n    'DAY',\n    '2024-01-01'::TIMESTAMP_NTZ,\n    CURRENT_TIMESTAMP()\n));\n\n-- Get statistical metrics\nSELECT * FROM TABLE(MODEL_MONITOR_STAT_METRIC(\n    'FTMP_PREDICTION_MONITOR',\n    'COUNT',\n    'DAY',\n    '2024-01-01'::TIMESTAMP_NTZ,\n    CURRENT_TIMESTAMP()\n));\n```\n\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Congratulations! You have completed the end-to-end ML workflow in Snowflake.\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "| Section | Capability | Key Takeaway |\n",
    "|---------|-----------|--------------|\n",
    "| 1. Setup | Snowpark Session | Python runs natively in Snowflake |\n",
    "| 2. Data Exploration | Snowpark DataFrames | Pandas-like syntax with Snowflake scale |\n",
    "| 3. Feature Engineering | Feature Store | Reusable, governed features |\n",
    "| 4. Preprocessing | ML Transformers | StandardScaler, OrdinalEncoder, Pipeline |\n",
    "| 5. Experiment Tracking | MLflow Integration | Track experiments without external tools |\n",
    "| 6. Model Training | Snowpark ML | XGBoost, LightGBM, and more |\n",
    "| 7. Model Registry | Version Control | Governed model deployment |\n",
    "| 8. Batch Scoring | Model Inference | Feature Store + Registry for production |\n",
    "| 9. Orchestration | Tasks | Automated, scheduled pipelines |\n",
    "| 10. Monitoring | Prediction Quality | Detect drift and degradation |\n",
    "\n",
    "### Objects Created in This Workshop\n",
    "\n",
    "| Object | Type | Purpose |\n",
    "|--------|------|---------|\n",
    "| `ML_WORKFLOW_DEMO.WORKSHOP` | Schema | Workshop namespace |\n",
    "| `TRAINING_BASE` | Table | Joined training data |\n",
    "| `DAILY_FEATURES` | Table | Engineered features |\n",
    "| `FTMP_PREDICTIONS` | Table | Model predictions |\n",
    "| `DAILY_DATE` | Entity | Feature Store entity |\n",
    "| `DAILY_CONVERSION_FEATURES` | Feature View | Registered features |\n",
    "| `FTMP_CONVERSION_PREDICTOR` | Model | Registered XGBoost model |\n",
    "| `DAILY_FTMP_SCORING` | Task | Scheduled scoring job |\n",
    "| `PREDICTION_MONITORING` | View | Monitoring dashboard |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Explore the UI**: Navigate to AI/ML in Snowsight to see your experiments, models, and features\n",
    "2. **Try Different Models**: Experiment with LightGBM, RandomForest, or other algorithms\n",
    "3. **Add More Features**: Enhance the feature engineering with additional transformations\n",
    "4. **Production Deployment**: Activate the task and set up alerts for monitoring\n",
    "5. **Advanced Topics**: Explore CI/CD integration, A/B testing, and model explainability\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Snowflake ML Documentation](https://docs.snowflake.com/en/guides-overview-ml)\n",
    "- [Snowpark Python API Reference](https://docs.snowflake.com/en/developer-guide/snowpark/python/index)\n",
    "- [Feature Store Guide](https://docs.snowflake.com/en/developer-guide/snowflake-ml/feature-store)\n",
    "- [Model Registry Guide](https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry)\n",
    "\n",
    "---\n",
    "\n",
    "**Thank you for participating in this workshop!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions for monitoring\n",
    "final_predictions.write.save_as_table(\"FTMP_PREDICTIONS\", mode=\"overwrite\")\n",
    "print(\"Predictions saved to FTMP_PREDICTIONS table\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}